{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic_problem import LogicProblem\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "logic = LogicProblem(key_size=16, loss_fn=loss_fn, embed_dim=64, num_FIN_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.9333470463752747\n",
      "Epoch 1 loss: 0.7650517821311951\n",
      "Epoch 2 loss: 0.7705124616622925\n",
      "Epoch 3 loss: 0.7340700626373291\n",
      "Epoch 4 loss: 0.7286219596862793\n",
      "Epoch 5 loss: 0.7245119214057922\n",
      "Epoch 6 loss: 0.722831130027771\n",
      "Epoch 7 loss: 0.7199228405952454\n",
      "Epoch 8 loss: 0.7169090509414673\n",
      "Epoch 9 loss: 0.7163890600204468\n",
      "Epoch 10 loss: 0.7164049744606018\n",
      "Epoch 11 loss: 0.7132387757301331\n",
      "Epoch 12 loss: 0.7118897438049316\n",
      "Epoch 13 loss: 0.7118959426879883\n",
      "Epoch 14 loss: 0.7096830606460571\n",
      "Epoch 15 loss: 0.7088966965675354\n",
      "Epoch 16 loss: 0.7082410454750061\n",
      "Epoch 17 loss: 0.7076187133789062\n",
      "Epoch 18 loss: 0.7070009112358093\n",
      "Epoch 19 loss: 0.7066709995269775\n",
      "Epoch 20 loss: 0.705751895904541\n",
      "Epoch 21 loss: 0.7052425742149353\n",
      "Epoch 22 loss: 0.7047969698905945\n",
      "Epoch 23 loss: 0.7048948407173157\n",
      "Epoch 24 loss: 0.7040525078773499\n",
      "Epoch 25 loss: 0.7037178874015808\n",
      "Epoch 26 loss: 0.7035876512527466\n",
      "Epoch 27 loss: 0.7026305794715881\n",
      "Epoch 28 loss: 0.7030026316642761\n",
      "Epoch 29 loss: 0.7021468281745911\n",
      "Epoch 30 loss: 0.70270174741745\n",
      "Epoch 31 loss: 0.7023191452026367\n",
      "Epoch 32 loss: 0.7014245986938477\n",
      "Epoch 33 loss: 0.7011062502861023\n",
      "Epoch 34 loss: 0.7013242244720459\n",
      "Epoch 35 loss: 0.7011675834655762\n",
      "Epoch 36 loss: 0.7004790902137756\n",
      "Epoch 37 loss: 0.7002479434013367\n",
      "Epoch 38 loss: 0.7000808119773865\n",
      "Epoch 39 loss: 0.6996884942054749\n",
      "Epoch 40 loss: 0.7003100514411926\n",
      "Epoch 41 loss: 0.699982762336731\n",
      "Epoch 42 loss: 0.6993770003318787\n",
      "Epoch 43 loss: 0.6993440389633179\n",
      "Epoch 44 loss: 0.699564516544342\n",
      "Epoch 45 loss: 0.6988099813461304\n",
      "Epoch 46 loss: 0.6990786194801331\n",
      "Epoch 47 loss: 0.698722243309021\n",
      "Epoch 48 loss: 0.6987108588218689\n",
      "Epoch 49 loss: 0.6996992826461792\n",
      "Epoch 50 loss: 0.6989845037460327\n",
      "Epoch 51 loss: 0.6981069445610046\n",
      "Epoch 52 loss: 0.6985526084899902\n",
      "Epoch 53 loss: 0.6991606950759888\n",
      "Epoch 54 loss: 0.6981867551803589\n",
      "Epoch 55 loss: 0.697932243347168\n",
      "Epoch 56 loss: 0.697741687297821\n",
      "Epoch 57 loss: 0.6977766752243042\n",
      "Epoch 58 loss: 0.6985543370246887\n",
      "Epoch 59 loss: 0.6979374289512634\n",
      "Epoch 60 loss: 0.6974384188652039\n",
      "Epoch 61 loss: 0.697500467300415\n",
      "Epoch 62 loss: 0.6981323957443237\n",
      "Epoch 63 loss: 0.6991118788719177\n",
      "Epoch 64 loss: 0.6976535320281982\n",
      "Epoch 65 loss: 0.6972495317459106\n",
      "Epoch 66 loss: 0.6993133425712585\n",
      "Epoch 67 loss: 0.6983361840248108\n",
      "Epoch 68 loss: 0.696724534034729\n",
      "Epoch 69 loss: 0.6972255110740662\n",
      "Epoch 70 loss: 0.6970337629318237\n",
      "Epoch 71 loss: 0.6967191696166992\n",
      "Epoch 72 loss: 0.6965516805648804\n",
      "Epoch 73 loss: 0.6965550184249878\n",
      "Epoch 74 loss: 0.6966121196746826\n",
      "Epoch 75 loss: 0.6966261863708496\n",
      "Epoch 76 loss: 0.6968488097190857\n",
      "Epoch 77 loss: 0.6963740587234497\n",
      "Epoch 78 loss: 0.6963121294975281\n",
      "Epoch 79 loss: 0.6958231925964355\n",
      "Epoch 80 loss: 0.6967200040817261\n",
      "Epoch 81 loss: 0.6963657736778259\n",
      "Epoch 82 loss: 0.6965795159339905\n",
      "Epoch 83 loss: 0.696264386177063\n",
      "Epoch 84 loss: 0.6964048743247986\n",
      "Epoch 85 loss: 0.6959899067878723\n",
      "Epoch 86 loss: 0.6961367726325989\n",
      "Epoch 87 loss: 0.6958839893341064\n",
      "Epoch 88 loss: 0.6961480975151062\n",
      "Epoch 89 loss: 0.6972599029541016\n",
      "Epoch 90 loss: 0.696075975894928\n",
      "Epoch 91 loss: 0.6961793899536133\n",
      "Epoch 92 loss: 0.696969211101532\n",
      "Epoch 93 loss: 0.6961416006088257\n",
      "Epoch 94 loss: 0.6956881880760193\n",
      "Epoch 95 loss: 0.6963133811950684\n",
      "Epoch 96 loss: 0.6958747506141663\n",
      "Epoch 97 loss: 0.6956909894943237\n",
      "Epoch 98 loss: 0.6956263780593872\n",
      "Epoch 99 loss: 0.6957306265830994\n",
      "Epoch 100 loss: 0.6956650018692017\n",
      "Epoch 101 loss: 0.6955877542495728\n",
      "Epoch 102 loss: 0.6953780055046082\n",
      "Epoch 103 loss: 0.695537805557251\n",
      "Epoch 104 loss: 0.6963844299316406\n",
      "Epoch 105 loss: 0.6958367824554443\n",
      "Epoch 106 loss: 0.6953598856925964\n",
      "Epoch 107 loss: 0.6960639953613281\n",
      "Epoch 108 loss: 0.6953793168067932\n",
      "Epoch 109 loss: 0.6952893733978271\n",
      "Epoch 110 loss: 0.6951428651809692\n",
      "Epoch 111 loss: 0.6958219408988953\n",
      "Epoch 112 loss: 0.6950225234031677\n",
      "Epoch 113 loss: 0.6951559782028198\n",
      "Epoch 114 loss: 0.6951467990875244\n",
      "Epoch 115 loss: 0.6951694488525391\n",
      "Epoch 116 loss: 0.6950863599777222\n",
      "Epoch 117 loss: 0.6950696110725403\n",
      "Epoch 118 loss: 0.6950711011886597\n",
      "Epoch 119 loss: 0.6949033141136169\n",
      "Epoch 120 loss: 0.6951965093612671\n",
      "Epoch 121 loss: 0.6955521106719971\n",
      "Epoch 122 loss: 0.6950898170471191\n",
      "Epoch 123 loss: 0.6951197981834412\n",
      "Epoch 124 loss: 0.6947672367095947\n",
      "Epoch 125 loss: 0.6951956152915955\n",
      "Epoch 126 loss: 0.6950868368148804\n",
      "Epoch 127 loss: 0.6947711706161499\n",
      "Epoch 128 loss: 0.6948564648628235\n",
      "Epoch 129 loss: 0.6948414444923401\n",
      "Epoch 130 loss: 0.6948146820068359\n",
      "Epoch 131 loss: 0.6948489546775818\n",
      "Epoch 132 loss: 0.6947737336158752\n",
      "Epoch 133 loss: 0.6948278546333313\n",
      "Epoch 134 loss: 0.6948190331459045\n",
      "Epoch 135 loss: 0.6946878433227539\n",
      "Epoch 136 loss: 0.6946634650230408\n",
      "Epoch 137 loss: 0.6946348547935486\n",
      "Epoch 138 loss: 0.6944329738616943\n",
      "Epoch 139 loss: 0.694823145866394\n",
      "Epoch 140 loss: 0.6947935223579407\n",
      "Epoch 141 loss: 0.6948843002319336\n",
      "Epoch 142 loss: 0.6946470141410828\n",
      "Epoch 143 loss: 0.6951310038566589\n",
      "Epoch 144 loss: 0.6953703165054321\n",
      "Epoch 145 loss: 0.6946758031845093\n",
      "Epoch 146 loss: 0.6951460838317871\n",
      "Epoch 147 loss: 0.6953139305114746\n",
      "Epoch 148 loss: 0.6944054961204529\n",
      "Epoch 149 loss: 0.6945573091506958\n",
      "Epoch 150 loss: 0.694621741771698\n",
      "Epoch 151 loss: 0.6953258514404297\n",
      "Epoch 152 loss: 0.6943714618682861\n",
      "Epoch 153 loss: 0.6944908499717712\n",
      "Epoch 154 loss: 0.694554328918457\n",
      "Epoch 155 loss: 0.6947156190872192\n",
      "Epoch 156 loss: 0.6945611834526062\n",
      "Epoch 157 loss: 0.6945499181747437\n",
      "Epoch 158 loss: 0.6943346261978149\n",
      "Epoch 159 loss: 0.6944663524627686\n",
      "Epoch 160 loss: 0.6956832408905029\n",
      "Epoch 161 loss: 0.6947790384292603\n",
      "Epoch 162 loss: 0.6944977641105652\n",
      "Epoch 163 loss: 0.6950830221176147\n",
      "Epoch 164 loss: 0.6943656802177429\n",
      "Epoch 165 loss: 0.6943807601928711\n",
      "Epoch 166 loss: 0.6944047212600708\n",
      "Epoch 167 loss: 0.6943372488021851\n",
      "Epoch 168 loss: 0.6947401762008667\n",
      "Epoch 169 loss: 0.6942813396453857\n",
      "Epoch 170 loss: 0.6943244934082031\n",
      "Epoch 171 loss: 0.694548487663269\n",
      "Epoch 172 loss: 0.6943641304969788\n",
      "Epoch 173 loss: 0.6946560144424438\n",
      "Epoch 174 loss: 0.6943532228469849\n",
      "Epoch 175 loss: 0.6945928931236267\n",
      "Epoch 176 loss: 0.6940941214561462\n",
      "Epoch 177 loss: 0.6943098306655884\n",
      "Epoch 178 loss: 0.6942493319511414\n",
      "Epoch 179 loss: 0.694262683391571\n",
      "Epoch 180 loss: 0.6942890286445618\n",
      "Epoch 181 loss: 0.6940842866897583\n",
      "Epoch 182 loss: 0.694287121295929\n",
      "Epoch 183 loss: 0.6941726207733154\n",
      "Epoch 184 loss: 0.6941595077514648\n",
      "Epoch 185 loss: 0.6943907141685486\n",
      "Epoch 186 loss: 0.6941147446632385\n",
      "Epoch 187 loss: 0.6941901445388794\n",
      "Epoch 188 loss: 0.6940875053405762\n",
      "Epoch 189 loss: 0.6939603090286255\n",
      "Epoch 190 loss: 0.6945163607597351\n",
      "Epoch 191 loss: 0.6942757964134216\n",
      "Epoch 192 loss: 0.6941589117050171\n",
      "Epoch 193 loss: 0.6941573023796082\n",
      "Epoch 194 loss: 0.6939921379089355\n",
      "Epoch 195 loss: 0.6942400336265564\n",
      "Epoch 196 loss: 0.6943857073783875\n",
      "Epoch 197 loss: 0.6940675377845764\n",
      "Epoch 198 loss: 0.6940529346466064\n",
      "Epoch 199 loss: 0.694564938545227\n",
      "Epoch 200 loss: 0.6941183805465698\n",
      "Epoch 201 loss: 0.6940652132034302\n",
      "Epoch 202 loss: 0.6941150426864624\n",
      "Epoch 203 loss: 0.6943966746330261\n",
      "Epoch 204 loss: 0.6942605376243591\n",
      "Epoch 205 loss: 0.6940308809280396\n",
      "Epoch 206 loss: 0.6941023468971252\n",
      "Epoch 207 loss: 0.6941900849342346\n",
      "Epoch 208 loss: 0.6937865614891052\n",
      "Epoch 209 loss: 0.6940126419067383\n",
      "Epoch 210 loss: 0.6938864588737488\n",
      "Epoch 211 loss: 0.6939912438392639\n",
      "Epoch 212 loss: 0.6939108371734619\n",
      "Epoch 213 loss: 0.6939548254013062\n",
      "Epoch 214 loss: 0.6940327882766724\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mlogic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproblem_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\logic_problem.py:103\u001b[0m, in \u001b[0;36mLogicProblem.train\u001b[1;34m(self, epochs, problem_size, batch_size, lr)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    102\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 103\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    105\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\logic_problem.py:87\u001b[0m, in \u001b[0;36mLogicProblem.run_batch\u001b[1;34m(self, problem_size, batch_size)\u001b[0m\n\u001b[0;32m     82\u001b[0m outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: [],\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: []\n\u001b[0;32m     85\u001b[0m }\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size):\n\u001b[1;32m---> 87\u001b[0m     problem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mproblem_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;66;03m# transpose the output to (batch_size, obj_dim, num_objects)\u001b[39;00m\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;66;03m# Cause the loss function expects the output to be in this format\u001b[39;00m\n\u001b[0;32m     90\u001b[0m     problem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m problem[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\logic_problem.py:77\u001b[0m, in \u001b[0;36mLogicProblem.__call__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Convert labels from one-hot encoding to labels\u001b[39;00m\n\u001b[0;32m     74\u001b[0m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_mtx\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_mtx\u001b[39m\u001b[38;5;124m'\u001b[39m], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m { \n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tensors\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels_mtx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     79\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\model.py:94\u001b[0m, in \u001b[0;36mLogicModelMA.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# MA Layers\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m MA \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMA_list:\n\u001b[1;32m---> 94\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mMA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m# down-project to 3\u001b[39;00m\n\u001b[0;32m     97\u001b[0m Y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdp(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\model.py:284\u001b[0m, in \u001b[0;36mMixingAttention.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 284\u001b[0m     Z[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLN_Z[i](torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMHA[i][j](\n\u001b[0;32m    286\u001b[0m             X[i]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m), \n\u001b[0;32m    287\u001b[0m             X[j]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m    288\u001b[0m             X[j]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\\\n\u001b[0;32m    289\u001b[0m             \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# A_i = relu(FF(Z_i)+Z_i)W0_i\u001b[39;00m\n\u001b[0;32m    292\u001b[0m A \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\Coding\\AFRL-Airlift-Challenge\\logic_ops_exp\\model.py:285\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     Z[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLN_Z[i](torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m--> 285\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMHA\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\\\n\u001b[0;32m    289\u001b[0m             \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_keys], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# A_i = relu(FF(Z_i)+Z_i)W0_i\u001b[39;00m\n\u001b[0;32m    292\u001b[0m A \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[0;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[0;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32mc:\\Users\\C25Thomas.Blalock\\AppData\\Local\\anaconda3\\envs\\airlift-solution\\lib\\site-packages\\torch\\nn\\functional.py:5483\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5481\u001b[0m attn_output_weights \u001b[38;5;241m=\u001b[39m attn_output_weights\u001b[38;5;241m.\u001b[39mview(bsz, num_heads, tgt_len, src_len)\n\u001b[0;32m   5482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average_attn_weights:\n\u001b[1;32m-> 5483\u001b[0m     attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mattn_output_weights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batched:\n\u001b[0;32m   5486\u001b[0m     \u001b[38;5;66;03m# squeeze the output if input was unbatched\u001b[39;00m\n\u001b[0;32m   5487\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logic.train(epochs=256, problem_size=32, batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airlift-solution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
